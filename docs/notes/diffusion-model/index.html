<!DOCTYPE html>
<html lang="ja" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Diffusion Model | HideOut</title>
<meta name="keywords" content="論文読み, Machine Learning">
<meta name="description" content="概要 画像に逐次的にノイズを付加しランダムな画像を生成するプロセスを考える 上記の逆過程を推定することで、ランダムな画像から何らかのそれっぽい画">
<meta name="author" content="">
<link rel="canonical" href="https://ivorypawn.github.io/notes/diffusion-model/">
<link crossorigin="anonymous" href="https://ivorypawn.github.io/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="https://ivorypawn.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ivorypawn.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ivorypawn.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ivorypawn.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://ivorypawn.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css" integrity="sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js" integrity="sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>




<style>
    @media screen and (min-width: 769px) {
         
        .post-content input[type="checkbox"]:checked ~ label > img {
            transform: scale(1.6);
            cursor: zoom-out;
            position: relative;
            z-index: 999;
        }

        .post-content img.zoomCheck {
            transition: transform 0.15s ease;
            z-index: 999;
            cursor: zoom-in;
        }
    }
</style>


<link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
<meta property="og:title" content="Diffusion Model" />
<meta property="og:description" content="概要 画像に逐次的にノイズを付加しランダムな画像を生成するプロセスを考える 上記の逆過程を推定することで、ランダムな画像から何らかのそれっぽい画" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ivorypawn.github.io/notes/diffusion-model/" /><meta property="article:section" content="notes" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Diffusion Model"/>
<meta name="twitter:description" content="概要 画像に逐次的にノイズを付加しランダムな画像を生成するプロセスを考える 上記の逆過程を推定することで、ランダムな画像から何らかのそれっぽい画"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Notes",
      "item": "https://ivorypawn.github.io/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Diffusion Model",
      "item": "https://ivorypawn.github.io/notes/diffusion-model/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Diffusion Model",
  "name": "Diffusion Model",
  "description": "概要 画像に逐次的にノイズを付加しランダムな画像を生成するプロセスを考える 上記の逆過程を推定することで、ランダムな画像から何らかのそれっぽい画",
  "keywords": [
    "論文読み", "Machine Learning"
  ],
  "articleBody": "\r概要 画像に逐次的にノイズを付加しランダムな画像を生成するプロセスを考える 上記の逆過程を推定することで、ランダムな画像から何らかのそれっぽい画像を生成する DALL-E や Imagen などの画像生成は拡散モデルがベース\n（脳のモデル？） 推測の域を出ない話だが、現時点では拡散モデルが脳内の学習/推論の中心的な仕組みの最有力候補と思っている。学習が観測をデノイズするだけで容易で局所的な更新で実現可能。推論時に複数候補を生成でき（エネルギーモデル同様）条件付を後付けでき複数の推論の統合もでき、局所解にはまらない\n— Daisuke Okanohara / 岡野原 大輔 (@hillbig) August 11, 2022 岡野原さんの著書はいずれちゃんと読む。\n資料 Ho, J., Jain, A., \u0026 Abbeel, P.. (2020). Denoising Diffusion Probabilistic Models. Weng, L. (2021). What are Diffusion Models?. lilianweng.github.io. 第 10 回全日本コンピュータビジョン勉強会「生成モデル論文縛り読み会」A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud Completion 最近話題の\"Diffusion Model（拡散モデル）“について、簡潔にまとめてみた Shitong Luo, \u0026 Wei Hu (2021). Score-Based Point Cloud Denoising. In 2021 IEEE/CVF International Conference on Computer Vision (ICCV). IEEE. Awesome-Diffusion-Models（拡散モデルの応用研究をまとめたレポジトリ） Luo, C.. (2022). Understanding Diffusion Models: A Unified Perspective. 須山敦志 (2019)『ベイズ深層学習』講談社 準備 表記 ステップ $t$ における確率変数：$\\mathbf{x}_t\\in\\mathbb{R}^D$ $t=0,1,\\ldots ,T$ たとえば画像なら $D=\\text{Height}\\times\\text{Width}\\times\\text{RGB}$ など $\\mathbf{x}_{0:T}:=\\mathbf{x}_0,\\mathbf{x}_1,\\ldots,\\mathbf{x}_T$ 変数 $\\mathbf{x},\\mathbf{y}$ の同時分布 (joint distribution) $p(\\mathbf{x},\\mathbf{y})$ に対する以下の操作を周辺化(marginalization) と呼び、得られる $p(\\mathbf{y})$ を $\\mathbf{y}$ の ‘‘周辺分布’’(marginal distribution) と呼ぶ。 $$ p(\\mathbf{y})=\\int p(\\mathbf{x},\\mathbf{y})d\\mathbf{x} $$\nまた同時分布 $p(\\mathbf{x},\\mathbf{y})$ に対して $\\mathbf{y}$ に特定の値を定めたときの $\\mathbf{x}$ の確率分布を ‘‘条件つき分布’’(conditional distribution) と呼び、以下で定義する： $$ p(\\mathbf{x} | \\mathbf{y}):=\\frac{p(\\mathbf{x}, \\mathbf{y})}{p(\\mathbf{y})} $$\n周辺分布と条件つき分布は確率分布の条件を満たす。\nベイズ推論による統計解析では、$\\mathbf{X}$ を観測データ集合、$\\mathbf{Z}$ をパラメータや潜在変数をまとめた集合とするとき、まず確率モデル $p(\\mathbf{X},\\mathbf{Z})$ を何らかの仮定の下に設計し、学習や予測を事後分布 $p(\\mathbf{Z}|\\mathbf{X})$ の計算によって実現する。\nニューラルネットワークなど実用的なモデルの多くは $p(\\mathbf{Z}|\\mathbf{X})$ を解析的に求められない。したがって問題を後述の情報量の最適化にシフトし、勾配などを用いて近似的に求める手法がしばしば使われる（e.g. 変分推論）。\n拡散過程 概要で述べたノイズを付加／除去する過程は以下のように定式化される。\n画像の ‘‘真の’’ 確率密度関数：$q(\\mathbf{x}_0)$ 拡散モデルによって推定される確率密度関数：$p_\\theta(\\mathbf{x}_0)$ $\\theta$ は拡散モデルのパラメータ ノイズを付加していく過程：Forward diffusion process $q( \\mathbf{x}_t | \\mathbf{x}_{t-1} )$ ノイズを除去していく過程：Reverse diffusion process $p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$ 情報量 ある確率分布 $p(\\mathbf{x})$ に対し、関数 $f(\\mathbf{x})$ の期待値を以下で定義する。 $$ \\mathbb{E}_{p(\\mathbf{x})}[f(\\mathbf{x})]:=\\int f(\\mathbf{x})p(\\mathbf{x})d\\mathbf{x} $$\n確率分布 $p(\\mathbf{x}), q(\\mathbf{x})$ に対し、KL ダイバージェンス(Kullback-Leibler divergence) を以下で定義する。 $$ \\begin{align*} D_\\text{KL}[q(\\mathbf{x})||p(\\mathbf{x})] \u0026:= -\\int q(\\mathbf{x})\\log\\frac{p(\\mathbf{x})}{q(\\mathbf{x})}d\\mathbf{x} \\\\\\ \u0026= \\mathbb{E}_{q(\\mathbf{x})}[\\log q(\\mathbf{x})] - \\mathbb{E}_{q(\\mathbf{x})}[\\log p(\\mathbf{x})] \\end{align*} $$ KL ダイバージェンスは非負で、$p\\equiv q$ のときに限り $0$ になる。上界は存在しない。KL ダイバージェンスは $p,q$ の “近さ” のような概念だが、距離の公理などは満たさない。\n（参考） KL-divergence as an objective function 変分推論 事後分布を求めるために周辺尤度 $p(\\mathbf{X})=\\int p(\\mathbf{X},\\mathbf{Z})d\\mathbf{Z}$ を計算したいのだが、先述のとおり、モデルが複雑なときはこの積分を解析的に実行できない。\n変分推論法では、‘‘ELBO’’(Evidence Lower Bound; エビデンス下界) と呼ばれる対数周辺尤度 $\\log p(\\mathbf{X})$ の下界 $\\mathcal{L}(\\xi)$ を導入し、変分パラメータ $\\xi$（しばしば近似分布の平均や分散を表す）を最適化して ELBO を最大化することによって（対数）周辺尤度の近似解を得る。 $$ \\log p(\\mathbf{X})\\geq\\mathcal{L}(\\xi) $$\nよく使われる手法の一つは、事後分布 $p(\\mathbf{Z}|\\mathbf{X})$ のあるパラメータ $\\xi$ によって定まる分布 $q(\\mathbf{Z};\\xi)$ による近似であり、次の KL ダイバージェンスの最小化問題を解く。 $$ \\arg\\min_\\xi D_\\text{KL}[q(\\mathbf{Z};\\xi)||p(\\mathbf{Z}|\\mathbf{X})] $$ また対数周辺尤度は以下のように分解される。 $$ \\log p(\\mathbf{X})=\\mathcal{L}(\\xi)+D_\\text{KL}[q(\\mathbf{Z};\\xi)||p(\\mathbf{Z}|\\mathbf{X})], \\quad \\mathcal{L}(\\xi):=\\int q(\\mathbf{Z};\\xi)\\log\\frac{p(\\mathbf{X},\\mathbf{Z})}{q(\\mathbf{Z};\\xi)}d\\mathbf{Z} $$\n対数周辺尤度 $\\log p(\\mathbf{X})$ は $\\xi$ に依存しないため、この設定において ELBO の最大化は KL ダイバージェンスの最小化と等価になる。\n（余談） この界隈、ちょっと気に入らないのが何でもELBOの最大化から話を始める点ですね。KL divergenceの最小化と等価であることをまず抑えたほうが良いです。元々変分ベイズとして解こうとしていたのが無邪気に変なテク入れているうちにEMアルゴリズムになっちゃってたり色々残念な感じになりがちです。\n— 須山敦志 Suyama Atsushi (@sammy_suyama) August 28, 2022 ガウス分布 特別な確率分布として、以下の $D$ 次元ガウス分布が頻出する： $$ \\mathcal{N}(\\mathbf{x}|\\mathbf{\\mu},\\mathbf{\\Sigma}):=\\frac{1}{\\sqrt{(2\\pi)^D|\\mathbf{\\Sigma}|}}\\exp\\left(-\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu})^\\mathsf{T}\\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\mathbf{\\mu})\\right) $$ ここで $\\mathbf{\\mu}\\in\\mathbb{R}^D$ は平均、$\\mathbf{\\Sigma}\\in\\mathbb{R}^{D\\times D}$ は分散共分散行列。\nガウス分布の周辺分布や条件つき分布はガウス分布になる。ガウス分布は KL ダイバージェンスが解析的に求められるなど便利なため、論文でも多くの事前分布にガウス分布を仮定している。\n拡散モデル 元画像 $\\mathbf{x}_0$ にノイズを載せる処理を $T$ 回繰り返すことで、ランダムな画像 $\\mathbf{x}_T$ を生成することを考える。この逆過程を推定し、ランダムな画像 $\\mathbf{x}_T$ から意味のある画像 $\\mathbf{x}_0$ を生成することが目標である。\nForward diffusion process (Under Construction)\n",
  "wordCount" : "2193",
  "inLanguage": "ja",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ivorypawn.github.io/notes/diffusion-model/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "HideOut",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ivorypawn.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ivorypawn.github.io/" accesskey="h" title="HideOut (Alt + H)">HideOut</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://ivorypawn.github.io/posts/" title="posts">
                    <span>posts</span>
                </a>
            </li>
            <li>
                <a href="https://ivorypawn.github.io/notes/" title="notes">
                    <span>notes</span>
                </a>
            </li>
            <li>
                <a href="https://ivorypawn.github.io/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Diffusion Model
    </h1>
    <div class="post-meta">

</div>
  </header>

  
<div class="toc side left">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">目次</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#概要">概要</a>
      <ul>
        <li><a href="#脳のモデル">（脳のモデル？）</a></li>
      </ul>
    </li>
    <li><a href="#資料">資料</a></li>
    <li><a href="#準備">準備</a>
      <ul>
        <li><a href="#表記">表記</a></li>
        <li><a href="#拡散過程">拡散過程</a></li>
        <li><a href="#情報量">情報量</a>
          <ul>
            <li><a href="#参考">（参考）</a></li>
          </ul>
        </li>
        <li><a href="#変分推論">変分推論</a>
          <ul>
            <li><a href="#余談">（余談）</a></li>
          </ul>
        </li>
        <li><a href="#ガウス分布">ガウス分布</a></li>
      </ul>
    </li>
    <li><a href="#拡散モデル">拡散モデル</a>
      <ul>
        <li><a href="#forward-diffusion-process">Forward diffusion process</a></li>
      </ul>
    </li>
  </ul>
</nav>
        </div>
    </details>
</div>




 
  <div class="post-content"><p>




    
    <input type="checkbox" id="zoomCheck-b2f82" hidden>
    <label for="zoomCheck-b2f82">
        <img class="zoomCheck" loading="lazy" decoding="async"
            src="00.png" alt=""
             />
    </label>

</p>
<h2 id="概要">概要<a hidden class="anchor" aria-hidden="true" href="#概要">#</a></h2>
<ul>
<li>画像に逐次的にノイズを付加しランダムな画像を生成するプロセスを考える</li>
<li>上記の逆過程を推定することで、ランダムな画像から何らかのそれっぽい画像を生成する</li>
</ul>
<p>DALL-E や Imagen などの画像生成は拡散モデルがベース</p>
<h3 id="脳のモデル">（脳のモデル？）<a hidden class="anchor" aria-hidden="true" href="#脳のモデル">#</a></h3>
<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">推測の域を出ない話だが、現時点では拡散モデルが脳内の学習/推論の中心的な仕組みの最有力候補と思っている。学習が観測をデノイズするだけで容易で局所的な更新で実現可能。推論時に複数候補を生成でき（エネルギーモデル同様）条件付を後付けでき複数の推論の統合もでき、局所解にはまらない</p>&mdash; Daisuke Okanohara / 岡野原 大輔 (@hillbig) <a href="https://twitter.com/hillbig/status/1557687263160836096?ref_src=twsrc%5Etfw">August 11, 2022</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>岡野原さんの著書はいずれちゃんと読む。</p>
<h2 id="資料">資料<a hidden class="anchor" aria-hidden="true" href="#資料">#</a></h2>
<ol>
<li>Ho, J., Jain, A., &amp; Abbeel, P.. (2020). <a href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a>.</li>
<li>Weng, L. (2021). <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What are Diffusion Models?</a>. lilianweng.github.io.</li>
<li>第 10 回全日本コンピュータビジョン勉強会「生成モデル論文縛り読み会」<a href="https://speakerdeck.com/takmin/a-conditional-point-diffusion-refinement-paradigm-for-3d-point-cloud-completion">A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud Completion</a></li>
<li><a href="https://nakajimeee.hatenablog.com/entry/2022/01/03/041646">最近話題の&quot;Diffusion Model（拡散モデル）&ldquo;について、簡潔にまとめてみた</a></li>
<li>Shitong Luo, &amp; Wei Hu (2021). <a href="https://arxiv.org/abs/2107.10981">Score-Based Point Cloud Denoising</a>. In 2021 IEEE/CVF International Conference on Computer Vision (ICCV). IEEE.</li>
<li><a href="https://github.com/heejkoo/Awesome-Diffusion-Models">Awesome-Diffusion-Models</a>（拡散モデルの応用研究をまとめたレポジトリ）</li>
<li>Luo, C.. (2022). <a href="https://arxiv.org/abs/2208.11970">Understanding Diffusion Models: A Unified Perspective</a>.</li>
<li>須山敦志 (2019)『ベイズ深層学習』講談社</li>
</ol>
<h2 id="準備">準備<a hidden class="anchor" aria-hidden="true" href="#準備">#</a></h2>
<h3 id="表記">表記<a hidden class="anchor" aria-hidden="true" href="#表記">#</a></h3>
<ul>
<li>ステップ $t$ における確率変数：$\mathbf{x}_t\in\mathbb{R}^D$
<ul>
<li>$t=0,1,\ldots ,T$</li>
<li>たとえば画像なら $D=\text{Height}\times\text{Width}\times\text{RGB}$ など</li>
</ul>
</li>
<li>$\mathbf{x}_{0:T}:=\mathbf{x}_0,\mathbf{x}_1,\ldots,\mathbf{x}_T$</li>
</ul>
<p>変数 $\mathbf{x},\mathbf{y}$ の同時分布 (joint distribution) $p(\mathbf{x},\mathbf{y})$ に対する以下の操作を周辺化(marginalization) と呼び、得られる $p(\mathbf{y})$ を $\mathbf{y}$ の &lsquo;&lsquo;周辺分布&rsquo;&rsquo;(marginal distribution) と呼ぶ。
$$
p(\mathbf{y})=\int p(\mathbf{x},\mathbf{y})d\mathbf{x}
$$</p>
<p>また同時分布 $p(\mathbf{x},\mathbf{y})$ に対して $\mathbf{y}$ に特定の値を定めたときの $\mathbf{x}$ の確率分布を &lsquo;&lsquo;条件つき分布&rsquo;&rsquo;(conditional distribution) と呼び、以下で定義する：
$$
p(\mathbf{x} | \mathbf{y}):=\frac{p(\mathbf{x}, \mathbf{y})}{p(\mathbf{y})}
$$</p>
<p>周辺分布と条件つき分布は確率分布の条件を満たす。</p>
<p>ベイズ推論による統計解析では、$\mathbf{X}$ を観測データ集合、$\mathbf{Z}$ をパラメータや潜在変数をまとめた集合とするとき、まず確率モデル $p(\mathbf{X},\mathbf{Z})$ を何らかの仮定の下に設計し、学習や予測を事後分布 $p(\mathbf{Z}|\mathbf{X})$ の計算によって実現する。</p>
<p>ニューラルネットワークなど実用的なモデルの多くは $p(\mathbf{Z}|\mathbf{X})$ を解析的に求められない。したがって問題を後述の情報量の最適化にシフトし、勾配などを用いて近似的に求める手法がしばしば使われる（e.g. 変分推論）。</p>
<h3 id="拡散過程">拡散過程<a hidden class="anchor" aria-hidden="true" href="#拡散過程">#</a></h3>
<p>概要で述べたノイズを付加／除去する過程は以下のように定式化される。</p>
<ul>
<li>画像の &lsquo;&lsquo;真の&rsquo;&rsquo; 確率密度関数：$q(\mathbf{x}_0)$</li>
<li>拡散モデルによって推定される確率密度関数：$p_\theta(\mathbf{x}_0)$
<ul>
<li>$\theta$ は拡散モデルのパラメータ</li>
</ul>
</li>
<li>ノイズを付加していく過程：<em>Forward diffusion process</em> $q( \mathbf{x}_t | \mathbf{x}_{t-1} )$</li>
<li>ノイズを除去していく過程：<em>Reverse diffusion process</em> $p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)$</li>
</ul>
<h3 id="情報量">情報量<a hidden class="anchor" aria-hidden="true" href="#情報量">#</a></h3>
<p>ある確率分布 $p(\mathbf{x})$ に対し、関数 $f(\mathbf{x})$ の期待値を以下で定義する。
$$
\mathbb{E}_{p(\mathbf{x})}[f(\mathbf{x})]:=\int f(\mathbf{x})p(\mathbf{x})d\mathbf{x}
$$</p>
<p>確率分布 $p(\mathbf{x}), q(\mathbf{x})$ に対し、KL ダイバージェンス(Kullback-Leibler divergence) を以下で定義する。
$$
\begin{align*}
D_\text{KL}[q(\mathbf{x})||p(\mathbf{x})] &amp;:= -\int q(\mathbf{x})\log\frac{p(\mathbf{x})}{q(\mathbf{x})}d\mathbf{x} \\\
&amp;= \mathbb{E}_{q(\mathbf{x})}[\log q(\mathbf{x})] - \mathbb{E}_{q(\mathbf{x})}[\log p(\mathbf{x})]
\end{align*}
$$
KL ダイバージェンスは非負で、$p\equiv q$ のときに限り $0$ になる。上界は存在しない。KL ダイバージェンスは $p,q$ の &ldquo;近さ&rdquo; のような概念だが、距離の公理などは満たさない。</p>
<h4 id="参考">（参考）<a hidden class="anchor" aria-hidden="true" href="#参考">#</a></h4>
<ul>
<li><a href="https://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/">KL-divergence as an objective function</a></li>
</ul>
<h3 id="変分推論">変分推論<a hidden class="anchor" aria-hidden="true" href="#変分推論">#</a></h3>
<p>事後分布を求めるために周辺尤度 $p(\mathbf{X})=\int p(\mathbf{X},\mathbf{Z})d\mathbf{Z}$ を計算したいのだが、先述のとおり、モデルが複雑なときはこの積分を解析的に実行できない。</p>
<p>変分推論法では、&lsquo;&lsquo;ELBO&rsquo;&rsquo;(Evidence Lower Bound; エビデンス下界) と呼ばれる対数周辺尤度 $\log p(\mathbf{X})$ の下界 $\mathcal{L}(\xi)$ を導入し、変分パラメータ $\xi$（しばしば近似分布の平均や分散を表す）を最適化して ELBO を最大化することによって（対数）周辺尤度の近似解を得る。
$$
\log p(\mathbf{X})\geq\mathcal{L}(\xi)
$$</p>
<p>よく使われる手法の一つは、事後分布 $p(\mathbf{Z}|\mathbf{X})$ のあるパラメータ $\xi$ によって定まる分布 $q(\mathbf{Z};\xi)$ による近似であり、次の KL ダイバージェンスの最小化問題を解く。
$$
\arg\min_\xi D_\text{KL}[q(\mathbf{Z};\xi)||p(\mathbf{Z}|\mathbf{X})]
$$
また対数周辺尤度は以下のように分解される。
$$
\log p(\mathbf{X})=\mathcal{L}(\xi)+D_\text{KL}[q(\mathbf{Z};\xi)||p(\mathbf{Z}|\mathbf{X})], \quad \mathcal{L}(\xi):=\int q(\mathbf{Z};\xi)\log\frac{p(\mathbf{X},\mathbf{Z})}{q(\mathbf{Z};\xi)}d\mathbf{Z}
$$</p>
<p>対数周辺尤度 $\log p(\mathbf{X})$ は $\xi$ に依存しないため、この設定において ELBO の最大化は KL ダイバージェンスの最小化と等価になる。</p>
<h4 id="余談">（余談）<a hidden class="anchor" aria-hidden="true" href="#余談">#</a></h4>
<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">この界隈、ちょっと気に入らないのが何でもELBOの最大化から話を始める点ですね。KL divergenceの最小化と等価であることをまず抑えたほうが良いです。元々変分ベイズとして解こうとしていたのが無邪気に変なテク入れているうちにEMアルゴリズムになっちゃってたり色々残念な感じになりがちです。</p>&mdash; 須山敦志 Suyama Atsushi (@sammy_suyama) <a href="https://twitter.com/sammy_suyama/status/1563756088599920640?ref_src=twsrc%5Etfw">August 28, 2022</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<h3 id="ガウス分布">ガウス分布<a hidden class="anchor" aria-hidden="true" href="#ガウス分布">#</a></h3>
<p>特別な確率分布として、以下の $D$ 次元ガウス分布が頻出する：
$$
\mathcal{N}(\mathbf{x}|\mathbf{\mu},\mathbf{\Sigma}):=\frac{1}{\sqrt{(2\pi)^D|\mathbf{\Sigma}|}}\exp\left(-\frac{1}{2}(\mathbf{x}-\mathbf{\mu})^\mathsf{T}\mathbf{\Sigma}^{-1}(\mathbf{x}-\mathbf{\mu})\right)
$$
ここで $\mathbf{\mu}\in\mathbb{R}^D$ は平均、$\mathbf{\Sigma}\in\mathbb{R}^{D\times D}$ は分散共分散行列。</p>
<p>ガウス分布の周辺分布や条件つき分布はガウス分布になる。ガウス分布は KL ダイバージェンスが解析的に求められるなど便利なため、論文でも多くの事前分布にガウス分布を仮定している。</p>
<h2 id="拡散モデル">拡散モデル<a hidden class="anchor" aria-hidden="true" href="#拡散モデル">#</a></h2>
<p>元画像 $\mathbf{x}_0$ にノイズを載せる処理を $T$ 回繰り返すことで、ランダムな画像 $\mathbf{x}_T$ を生成することを考える。この逆過程を推定し、ランダムな画像 $\mathbf{x}_T$ から意味のある画像 $\mathbf{x}_0$ を生成することが目標である。</p>
<h3 id="forward-diffusion-process">Forward diffusion process<a hidden class="anchor" aria-hidden="true" href="#forward-diffusion-process">#</a></h3>
<p>(Under Construction)</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://ivorypawn.github.io/tags/%E8%AB%96%E6%96%87%E8%AA%AD%E3%81%BF/">論文読み</a></li>
      <li><a href="https://ivorypawn.github.io/tags/machine-learning/">Machine Learning</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://ivorypawn.github.io/">HideOut</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'コピー';

        function copyingDone() {
            copybutton.innerHTML = 'コピーされました!';
            setTimeout(() => {
                copybutton.innerHTML = 'コピー';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
